{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics as stats\n",
    "from scipy import optimize\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "#To introduce a range of 3D plots, we need to import another library\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "# The following line makes the images a bit larger than default - works better on a large screen\n",
    "plt.rcParams['figure.figsize'] = 10,10\n",
    "\n",
    "import astropy\n",
    "from astropy.io import fits\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "import  H_alpha as ha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Home Directory is set to: /Users/kiradavidoff/code/astrophysics/PROJECT_HALPHA/\n"
     ]
    }
   ],
   "source": [
    "# fits file in the same folder with python notebook\n",
    "home_dir = os.getcwd()+'/'\n",
    "print (\"The Home Directory is set to:\", home_dir) # check the home directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Dark_files, Dark_images, Dark_names = ha.dark()\n",
    "Bias_files, Bias_images, Bias_names= ha.bias()\n",
    "Light_file, Light_images, Light_names= ha.lights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subtract the mean bias from all frames\n",
    "Dark_images_bs = Dark_images - np.mean(Bias_images, axis=0)\n",
    "\n",
    "# substract the Dark frame from the Light images with bias subtracted\n",
    "Light_images_correct = Light_images - np.mean(Dark_images_bs, axis=0)- np.mean(Bias_images, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_dbl():\n",
    "    sigma_dark = np.sqrt(np.mean(Dark_images_bs, axis=0)) / np.sqrt(np.abs(len(Dark_images_bs)))\n",
    "    sigma_Bias = np.std(Bias_images,axis=0) / np.sqrt(len(Bias_images))\n",
    "    sigma_signal= np.sqrt(np.abs(Light_images_correct[image_number]))\n",
    "    sigma_dark_cor= np.sqrt(sigma_dark**2+sigma_Bias**2)\n",
    "    noise= np.sqrt(sigma_dark_cor**2+sigma_Bias**2+sigma_signal**2)\n",
    "    return noise\n",
    "\n",
    "def back(noise):\n",
    "\n",
    "\n",
    "    sigma_b1= noise[513:596,0:2048][10:24]\n",
    "    sigma_b2= noise[513:596,0:2048][63:77]\n",
    "\n",
    "    sigmab = np.concatenate([sigma_b1, sigma_b2], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    propagated_error =np.sqrt( np.mean(sigmab)**2 + noise[513:596,0:2048]**2)\n",
    "    noise_sqrt=np.sqrt(np.sum(propagated_error**2,axis=0))/len(np.sqrt(np.sum(propagated_error**2,axis=0)))\n",
    "    return noise_sqrt/np.sqrt(2048)\n",
    "\n",
    "\n",
    "def img():\n",
    "    background_1= np.mean(Light_images_correct[image_number][513:596,0:2048][10:24])\n",
    "    background_2= np.mean(Light_images_correct[image_number][513:596,0:2048][63:77])\n",
    "\n",
    "    alf_Dra_p002_02= Light_images_correct[image_number][520:590,0:2048] - (background_1+ background_2)/2\n",
    "    return np.sum(alf_Dra_p002_02, axis=0)\n",
    "\n",
    "\n",
    "def chi(continium_normarlised,normalised_err):\n",
    "    # Initialize lists to store results\n",
    "    H_alpha = []\n",
    "    H_err = []\n",
    "    chi2_left = []\n",
    "    chi2_right = []\n",
    "    chi2_increase = []\n",
    "    chi2_decrease = []\n",
    "\n",
    "\n",
    "\n",
    "    # Ensure x values are properly initialized\n",
    "    x = np.arange(0, len(continium_normarlised))\n",
    "\n",
    "    # First loop: shifting range leftward\n",
    "    for i in range(500):\n",
    "        # Select data range\n",
    "        mask = (x > 600 - i) & (x < 1600 - i)\n",
    "        sample_nw = continium_normarlised[mask]\n",
    "        x_range = x[mask]\n",
    "        sigma_range = normalised_err[mask]\n",
    "\n",
    "        # Initial guess for Lorentzian parameters: [Amplitude, Peak Position, Width, Offset]\n",
    "        initial_guess = [-1, -3, 1000, 5]\n",
    "\n",
    "        # Fit Lorentzian curve\n",
    "        try:\n",
    "            popt, pcov = optimize.curve_fit(ha.Lorentz, x_range, sample_nw, p0=initial_guess, maxfev=10000, sigma=sigma_range)\n",
    "            line_shape = ha.Lorentz(x, *popt)  # Fix: use `x_range` instead of undefined `x_slice`\n",
    "\n",
    "            # Extract fitted parameters\n",
    "            l0, l1, l2, l3 = popt\n",
    "\n",
    "            # Store results\n",
    "            H_alpha.append(l1)\n",
    "            H_err.append(np.sqrt(np.diag(pcov))[1])\n",
    "            chi2_left.append(ha.chi2_red(ha.residuals(continium_normarlised, line_shape), 4, normalised_err))\n",
    "\n",
    "        except RuntimeError:\n",
    "            print(f\"Fit failed at iteration {i}\")\n",
    "\n",
    "    # Second loop: shifting range rightward\n",
    "    for i in range(500):\n",
    "        # Select data range\n",
    "        mask = (x > (600 + i)) & (x < (1600 + i))\n",
    "        sample_nw = continium_normarlised[mask]\n",
    "        x_range = x[mask]\n",
    "        sigma_range = normalised_err[mask]\n",
    "\n",
    "        # Initial guess for Lorentzian parameters\n",
    "\n",
    "\n",
    "        # Fit Lorentzian curve\n",
    "        try:\n",
    "            popt, pcov = optimize.curve_fit(ha.Lorentz, x_range, sample_nw, p0=initial_guess, maxfev=10000, sigma=sigma_range)\n",
    "            line_shaped = ha.Lorentz(x, *popt)  # Fix: use `x_range` instead of undefined `x_slice`\n",
    "\n",
    "            # Extract fitted parameters\n",
    "            l0, l1, l2, l3 = popt\n",
    "\n",
    "            # Store results\n",
    "            H_alpha.append(l1)\n",
    "            H_err.append(np.sqrt(np.diag(pcov))[1])\n",
    "            chi2_right.append(ha.chi2_red(ha.residuals(continium_normarlised, line_shaped), 4, normalised_err))\n",
    "\n",
    "        except RuntimeError:\n",
    "            print(f\"Fit failed at iteration {i}\")\n",
    "\n",
    "    # First loop: increasing the range\n",
    "    for i in range(len(continium_normarlised)):\n",
    "        # Select data range\n",
    "        mask = (x > 600 - i) & (x < 1600 + i)\n",
    "        sample_nw = continium_normarlised[mask]\n",
    "        x_range = x[mask]\n",
    "        sigma_range = normalised_err[mask]\n",
    "\n",
    "        # Initial guess for Lorentzian parameters: [Amplitude, Peak Position, Width, Offset]\n",
    "\n",
    "\n",
    "        # Fit Lorentzian curve\n",
    "        try:\n",
    "            popt, pcov = optimize.curve_fit(ha.Lorentz, x_range, sample_nw, p0=initial_guess, maxfev=10000, sigma=sigma_range)\n",
    "            line_shaped = ha.Lorentz(x, *popt)  # Fix: use `x_range` instead of undefined `x_slice`\n",
    "\n",
    "            # Extract fitted parameters\n",
    "            l0, l1, l2, l3 = popt\n",
    "\n",
    "            # Store results\n",
    "            H_alpha.append(l1)\n",
    "            H_err.append(np.sqrt(np.diag(pcov))[1])\n",
    "            chi2_increase.append(ha.chi2_red(ha.residuals(continium_normarlised, line_shaped), 4, normalised_err))\n",
    "\n",
    "        except RuntimeError:\n",
    "            print(f\"Fit failed at iteration {i}\")\n",
    "\n",
    "    # Second loop: decreasing the range\n",
    "    for i in range(400):\n",
    "        # Select data range\n",
    "        mask = (x > (600 + i)) & (x < (1600 - i))\n",
    "        sample_nw = continium_normarlised[mask]\n",
    "        x_range = x[mask]\n",
    "        sigma_range = normalised_err[mask]\n",
    "\n",
    "        # Initial guess for Lorentzian parameters\n",
    "\n",
    "\n",
    "        # Fit Lorentzian curve\n",
    "        try:\n",
    "            popt, pcov = optimize.curve_fit(ha.Lorentz, x_range, sample_nw, p0=initial_guess, maxfev=10000, sigma=sigma_range)\n",
    "            line_shaped = ha.Lorentz(x, *popt)  # Fix: use `x_range` instead of undefined `x_slice`\n",
    "\n",
    "            # Extract fitted parameters\n",
    "            l0, l1, l2, l3 = popt\n",
    "\n",
    "            # Store results\n",
    "            H_alpha.append(l1)\n",
    "            H_err.append(np.sqrt(np.diag(pcov))[1])\n",
    "            chi2_decrease.append(ha.chi2_red(ha.residuals(continium_normarlised, line_shaped), 4, normalised_err))\n",
    "\n",
    "        except RuntimeError:\n",
    "            print(f\"Fit failed at iteration {i}\")\n",
    "\n",
    "    chi2_min=[min(chi2_increase),min(chi2_decrease), min(chi2_left),min(chi2_right)]\n",
    "    if min(chi2_min)==chi2_min[0]:\n",
    "        print('increase')\n",
    "        mask = (x > 600 - np.where(np.array(chi2_increase)==np.min(chi2_increase))[0][0]) & ( x < 1600 + np.where(np.array(chi2_increase)==np.min(chi2_increase))[0][0])\n",
    "        sample_nw = continium_normarlised[mask]\n",
    "        x_range = x[mask]\n",
    "        sigma_range = normalised_err[mask]\n",
    "\n",
    "    if min(chi2_min)==chi2_min[1]:\n",
    "        print('decrease')\n",
    "        mask = (x > 600 - np.where(np.array(chi2_decrease)==np.min(chi2_decrease))[0][0]) & ( x < 1600 + np.where(np.array(chi2_decrease)==np.min(chi2_decrease))[0][0])\n",
    "        sample_nw = continium_normarlised[mask]\n",
    "        x_range = x[mask]\n",
    "        sigma_range = normalised_err[mask]\n",
    "\n",
    "    if min(chi2_min)==chi2_min[2]:\n",
    "        print('left')\n",
    "        mask = (x > 600 - np.where(np.array(chi2_left)==np.min(chi2_left))[0][0]) & ( x < 1600 + np.where(np.array(chi2_left)==np.min(chi2_left))[0][0])\n",
    "        sample_nw = continium_normarlised[mask]\n",
    "        x_range = x[mask]\n",
    "        sigma_range = normalised_err[mask]\n",
    "\n",
    "    if min(chi2_min)==chi2_min[-1]:\n",
    "        print('right')\n",
    "        mask = (x > 600 - np.where(np.array(chi2_right)==np.min(chi2_right))[0][0]) & ( x < 1600 + np.where(np.array(chi2_right)==np.min(chi2_right))[0][0])\n",
    "        sample_nw = continium_normarlised[mask]\n",
    "        x_range = x[mask]\n",
    "        sigma_range = normalised_err[mask]\n",
    "\n",
    "    # Initial guess for Lorentzian parameters: [Amplitude, Peak Position, Width, Offset]\n",
    "\n",
    "\n",
    "\n",
    "    popt, pcov = optimize.curve_fit(ha.Lorentz, x_range, sample_nw, p0=initial_guess, maxfev=10000, sigma=sigma_range)\n",
    "\n",
    "\n",
    "    return popt, pcov, sample_nw, sigma_range, x_range\n",
    "\n",
    "def final(popt, pcov, sample_nw, sigma_range, x_range):\n",
    "    amplitude_cov = np.sqrt(np.diag(pcov))[1]\n",
    "    position_cov = np.sqrt(np.diag(pcov))[2]\n",
    "\n",
    "    amplitude, position= popt[1],popt[2]\n",
    "    amplitude_err,position_err= ha.compute_param_uncertainty(1, 50,0.0001, x_range, sample_nw, sigma_range, popt),ha.compute_param_uncertainty(2, 50,0.001, x_range, sample_nw, sigma_range, popt)\n",
    "\n",
    "    positionLambda, positionLambdaError = WavelengthConverter(position, position_err, march = True)\n",
    "    print('CHI')\n",
    "    print(positionLambda, positionLambdaError)\n",
    "    positionLambda, positionLambdaErrorCov = WavelengthConverter(position, position_cov, march = True )\n",
    "    print('COV')\n",
    "    print(positionLambda, positionLambdaErrorCov)\n",
    "\n",
    "\n",
    "    print(f'ImageNumber = {1}\\n\\n')\n",
    "\n",
    "    print('               VALUE              CHI SQUARED ERROR     COVARIANCE MATRIX ERROR')\n",
    "    print(f\"amplitude   {amplitude} +- {amplitude_err} +- {amplitude_cov}\")\n",
    "    print(f\"position     {position} +- {position_err}    +- {position_cov}\")\n",
    "    print(f\"\\nposition (Angstrom):  {positionLambda}+- {positionLambdaError}+- {positionLambdaErrorCov}\")\n",
    "\n",
    "\n",
    "    print('\\n')\n",
    "    print(f'SN (CHI): {np.abs(amplitude/amplitude_err)}')\n",
    "    print(f'SN (COV): {np.abs(amplitude/amplitude_cov)}')\n",
    "\n",
    "\n",
    "def double_lorentz(x, amp1, center1, width1, amp2, center2, width2, offset):\n",
    "    lorentz1 = amp1 / (1 + ((x - center1) / width1) ** 2)\n",
    "    lorentz2 = amp2 / (1 + ((x - center2) / width2) ** 2)\n",
    "    return lorentz1 + lorentz2 + offset\n",
    "\n",
    "def chi_2(continium_normarlised,normalised_err):\n",
    "\n",
    "\n",
    "    # Initialize lists to store results\n",
    "    H_alpha = []\n",
    "    H_err = []\n",
    "    chi2_left = []\n",
    "    chi2_right = []\n",
    "    chi2_increase = []\n",
    "    chi2_decrease = []\n",
    "\n",
    "    initial_guess = [-0.5, 950, 100, -0.3, 1050, 120, 1]\n",
    "    # Ensure x values are properly initialized\n",
    "    x = np.arange(0, len(continium_normarlised))\n",
    "\n",
    "    # First loop: shifting range leftward\n",
    "    for i in range(500):\n",
    "        # Select data range\n",
    "        mask = (x > 600 - i) & (x < 1600 - i)\n",
    "        sample_nw = continium_normarlised[mask]\n",
    "        x_range = x[mask]\n",
    "        sigma_range = normalised_err[mask]\n",
    "\n",
    "        # Initial guess for Lorentzian parameters: [Amplitude, Peak Position, Width, Offset]\n",
    "        initial_guess = [-0.5, 950, 100, -0.3, 1050, 120, 1]\n",
    "\n",
    "        # Fit Lorentzian curve\n",
    "        try:\n",
    "            popt, pcov = optimize.curve_fit(double_lorentz, x_range, sample_nw, p0=initial_guess, maxfev=10000, sigma=sigma_range)\n",
    "            line_shape = double_lorentz(x, *popt)  # Fix: use `x_range` instead of undefined `x_slice`\n",
    "\n",
    "\n",
    "\n",
    "            # Store results\n",
    "\n",
    "            H_err.append(np.sqrt(np.diag(pcov))[1])\n",
    "            chi2_left.append(ha.chi2_red(ha.residuals(continium_normarlised, line_shape), 4, normalised_err))\n",
    "\n",
    "        except RuntimeError:\n",
    "            print(f\"Fit failed at iteration {i}\")\n",
    "\n",
    "    # Second loop: shifting range rightward\n",
    "    for i in range(500):\n",
    "        # Select data range\n",
    "        mask = (x > (600 + i)) & (x < (1600 + i))\n",
    "        sample_nw = continium_normarlised[mask]\n",
    "        x_range = x[mask]\n",
    "        sigma_range = normalised_err[mask]\n",
    "\n",
    "        # Initial guess for Lorentzian parameters\n",
    "\n",
    "\n",
    "        # Fit Lorentzian curve\n",
    "        try:\n",
    "            popt, pcov = optimize.curve_fit(double_lorentz, x_range, sample_nw, p0=initial_guess, maxfev=10000, sigma=sigma_range)\n",
    "            line_shaped = double_lorentz(x, *popt)  # Fix: use `x_range` instead of undefined `x_slice`\n",
    "\n",
    "\n",
    "\n",
    "            H_err.append(np.sqrt(np.diag(pcov))[1])\n",
    "            chi2_right.append(ha.chi2_red(ha.residuals(continium_normarlised, line_shaped), 4, normalised_err))\n",
    "\n",
    "        except RuntimeError:\n",
    "            print(f\"Fit failed at iteration {i}\")\n",
    "\n",
    "    # First loop: increasing the range\n",
    "    for i in range(len(continium_normarlised)):\n",
    "        # Select data range\n",
    "        mask = (x > 600 - i) & (x < 1600 + i)\n",
    "        sample_nw = continium_normarlised[mask]\n",
    "        x_range = x[mask]\n",
    "        sigma_range = normalised_err[mask]\n",
    "\n",
    "        # Initial guess for Lorentzian parameters: [Amplitude, Peak Position, Width, Offset]\n",
    "\n",
    "\n",
    "        # Fit Lorentzian curve\n",
    "        try:\n",
    "            popt, pcov = optimize.curve_fit(double_lorentz, x_range, sample_nw, p0=initial_guess, maxfev=10000, sigma=sigma_range)\n",
    "            line_shaped = double_lorentz(x, *popt)  # Fix: use `x_range` instead of undefined `x_slice`\n",
    "\n",
    "\n",
    "\n",
    "            H_err.append(np.sqrt(np.diag(pcov))[1])\n",
    "            chi2_increase.append(ha.chi2_red(ha.residuals(continium_normarlised, line_shaped), 4, normalised_err))\n",
    "\n",
    "        except RuntimeError:\n",
    "            print(f\"Fit failed at iteration {i}\")\n",
    "\n",
    "    # Second loop: decreasing the range\n",
    "    for i in range(400):\n",
    "        # Select data range\n",
    "        mask = (x > (600 + i)) & (x < (1600 - i))\n",
    "        sample_nw = continium_normarlised[mask]\n",
    "        x_range = x[mask]\n",
    "        sigma_range = normalised_err[mask]\n",
    "\n",
    "        # Initial guess for Lorentzian parameters\n",
    "\n",
    "\n",
    "        # Fit Lorentzian curve\n",
    "        try:\n",
    "            popt, pcov = optimize.curve_fit(double_lorentz, x_range, sample_nw, p0=initial_guess, maxfev=10000, sigma=sigma_range)\n",
    "            line_shaped = double_lorentz(x, *popt)  # Fix: use `x_range` instead of undefined `x_slice`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            H_err.append(np.sqrt(np.diag(pcov))[1])\n",
    "            chi2_decrease.append(ha.chi2_red(ha.residuals(continium_normarlised, line_shaped), 4, normalised_err))\n",
    "\n",
    "        except RuntimeError:\n",
    "            print(f\"Fit failed at iteration {i}\")\n",
    "    chi2_min=[min(chi2_increase),min(chi2_decrease), min(chi2_left),min(chi2_right)]\n",
    "    if min(chi2_min)==chi2_min[0]:\n",
    "        print('increase')\n",
    "        mask = (x > 600 - np.where(np.array(chi2_increase)==np.min(chi2_increase))[0][0]) & ( x < 1600 + np.where(np.array(chi2_increase)==np.min(chi2_increase))[0][0])\n",
    "        sample_nw = continium_normarlised[mask]\n",
    "        x_range = x[mask]\n",
    "        sigma_range = normalised_err[mask]\n",
    "\n",
    "    if min(chi2_min)==chi2_min[1]:\n",
    "        print('decrease')\n",
    "        mask = (x > 600 - np.where(np.array(chi2_decrease)==np.min(chi2_decrease))[0][0]) & ( x < 1600 + np.where(np.array(chi2_decrease)==np.min(chi2_decrease))[0][0])\n",
    "        sample_nw = continium_normarlised[mask]\n",
    "        x_range = x[mask]\n",
    "        sigma_range = normalised_err[mask]\n",
    "\n",
    "    if min(chi2_min)==chi2_min[2]:\n",
    "        print('left')\n",
    "        mask = (x > 600 - np.where(np.array(chi2_left)==np.min(chi2_left))[0][0]) & ( x < 1600 + np.where(np.array(chi2_left)==np.min(chi2_left))[0][0])\n",
    "        sample_nw = continium_normarlised[mask]\n",
    "        x_range = x[mask]\n",
    "        sigma_range = normalised_err[mask]\n",
    "\n",
    "    if min(chi2_min)==chi2_min[-1]:\n",
    "        print('right')\n",
    "        mask = (x > 600 - np.where(np.array(chi2_right)==np.min(chi2_right))[0][0]) & ( x < 1600 + np.where(np.array(chi2_right)==np.min(chi2_right))[0][0])\n",
    "        sample_nw = continium_normarlised[mask]\n",
    "        x_range = x[mask]\n",
    "        sigma_range = normalised_err[mask]\n",
    "\n",
    "\n",
    "\n",
    "    popt, pcov = optimize.curve_fit(double_lorentz, x_range, sample_nw, p0=initial_guess, maxfev=10000, sigma=sigma_range)\n",
    "\n",
    "\n",
    "    return popt, pcov, sample_nw, sigma_range, x_range\n",
    "\n",
    "def compute_param_uncertainty_double_lorentz(index, delta_range, step, xx, data, error, fit_parameter):\n",
    "    \"\"\"\n",
    "    Work out the uncertainty in one of the parameters by varying it over a range using a double Lorentzian fit.\n",
    "\n",
    "    input:\n",
    "    index: index of the parameter (0 = amp1, 1 = center1, 2 = width1, 3 = amp2, 4 = center2, 5 = width2, 6 = offset)\n",
    "    delta_range: the range which parameter varies\n",
    "    step: difference between each variation\n",
    "    xx: the independent variable array (e.g., x-axis)\n",
    "    data: observed data\n",
    "    error: the error in the data\n",
    "    fit_parameter: optimized parameters (amp1, center1, width1, amp2, center2, width2, offset)\n",
    "\n",
    "    Returns:\n",
    "    uncertainty: computed uncertainty of the parameter.\n",
    "    \"\"\"\n",
    "    # Calculate degrees of freedom\n",
    "    dof = len(xx) - len(fit_parameter)\n",
    "\n",
    "    # Create an array of variation for the specified parameter\n",
    "    base_value = fit_parameter[index]\n",
    "    parameter_range = np.arange(base_value - delta_range, base_value + delta_range, step)\n",
    "\n",
    "    # Empty list to store chi-square values\n",
    "    chi_sq = []\n",
    "\n",
    "    # Loop over the parameter range\n",
    "    for val in parameter_range:\n",
    "        # Change the variable parameter\n",
    "        parameter = fit_parameter.copy()\n",
    "        parameter[index] = val\n",
    "\n",
    "        # Fit the model using the current parameters\n",
    "        y_ = double_lorentz(xx, parameter[0], parameter[1], parameter[2], parameter[3], parameter[4], parameter[5], parameter[6])\n",
    "\n",
    "        # Calculate chi-square\n",
    "        chi_sq = ha.chi_square_calc(data, error, y_,chi_sq, 7)\n",
    "\n",
    "\n",
    "    # Use parameter error to compute the uncertainty\n",
    "    uncertainty = ha.parameter_error(chi_sq, parameter_range, base_value)\n",
    "    return uncertainty\n",
    "\n",
    "\n",
    "\n",
    "def sn_dl(continium_normarlised,normalised_err):\n",
    "    x,y=np.arange(0, len(continium_normarlised)), continium_normarlised\n",
    "\n",
    "\n",
    "    # Fit the Double Lorentzian\n",
    "    popt, pcov = curve_fit(double_lorentz, x, y, p0=[-0.7, 1100, 10, -0.7, 1100, 10, 10], sigma=normalised_err, maxfev=10000)\n",
    "\n",
    "\n",
    "\n",
    "    line_shaped= double_lorentz(x,*popt)\n",
    "    amplitude=popt[0]+popt[3]\n",
    "\n",
    "    err=np.sqrt(compute_param_uncertainty_double_lorentz(0, 50, 0.001, x, y, normalised_err, popt)**2+compute_param_uncertainty_double_lorentz(3, 50, 0.001, x, y, normalised_err, popt)**2)\n",
    "    print(ha.chi2_red(ha.residuals(continium_normarlised, line_shaped), 7, normalised_err))\n",
    "\n",
    "    return amplitude, err, popt, pcov\n",
    "\n",
    "def pos_dl(continium_normarlised, normalised_err):\n",
    "    x,y=np.arange(0, len(continium_normarlised)), continium_normarlised\n",
    "\n",
    "\n",
    "    # Fit the Double Lorentzian\n",
    "    popt,pcov = curve_fit(double_lorentz, x, y, p0=[-0.7, 1100, 10, -0.7, 1100, 10, 10], sigma=normalised_err,maxfev=10000)\n",
    "\n",
    "    err=np.sqrt((compute_param_uncertainty_double_lorentz(1, 50, 0.001, x, y, normalised_err, popt)**2+compute_param_uncertainty_double_lorentz(4, 50, 0.001, x, y, normalised_err, popt)**2)/4)\n",
    "\n",
    "\n",
    "    return (popt[1]+popt[4])/2, err, popt, pcov\n",
    "\n",
    "\n",
    "\n",
    "def final_double_lorentz(amplitude, amplitude_err_chi, position, position_err_chi, pcov, image_number=1):\n",
    "    \"\"\"\n",
    "    Mirror of your single-Lorentz 'final', but for two lines:\n",
    "    - amplitude = A1 + A2\n",
    "    - position  = (x01 + x02)/2\n",
    "    Uses pcov to compute covariance-based errors on these combined quantities.\n",
    "    \"\"\"\n",
    "    #  covariance-based uncertainties for combined params\n",
    "    amp_cov_var = pcov[0,0] + pcov[3,3] + 2.0*pcov[0,3]\n",
    "    amplitude_err_cov = np.sqrt(max(amp_cov_var, 0.0))\n",
    "\n",
    "    pos_cov_var = (pcov[1,1] + pcov[4,4] + 2.0*pcov[1,4]) / 4.0\n",
    "    position_err_cov = np.sqrt(max(pos_cov_var, 0.0))\n",
    "\n",
    "    #  wavelength conversion (both error types)\n",
    "    lam_chi, lam_err_chi = WavelengthConverter(position, position_err_chi, march=True)\n",
    "    lam_cov, lam_err_cov = WavelengthConverter(position, position_err_cov, march=True)\n",
    "\n",
    "\n",
    "    print(f'ImageNumber = {image_number}\\n')\n",
    "    print('               VALUE              CHI/MC ERROR           COVARIANCE-MATRIX ERROR')\n",
    "    print(f\"amplitude   {amplitude} +- {amplitude_err_chi}        +- {amplitude_err_cov}\")\n",
    "    print(f\"position    {position} +- {position_err_chi}         +- {position_err_cov}\")\n",
    "    print(f\"\\nposition (Angstrom):  {lam_chi} +- {lam_err_chi}      +- {lam_err_cov}\\n\")\n",
    "\n",
    "    # S/N both ways (use absolute to be safe with negative absorption depths)\n",
    "    sn_chi = np.abs(amplitude/amplitude_err_chi) if amplitude_err_chi != 0 else np.inf\n",
    "    sn_cov = np.abs(amplitude/amplitude_err_cov) if amplitude_err_cov != 0 else np.inf\n",
    "    print(f'SN (CHI): {sn_chi}')\n",
    "    print(f'SN (COV): {sn_cov}')\n",
    "\n",
    "\n",
    "def WavelengthConverter(x,xError, feb = False, march = False):\n",
    "    \"\"\"\n",
    "    Convert pixel positions to wavelengths using a quadratic dispersion relation.\n",
    "\n",
    "    args:\n",
    "        x (array-like): Pixel positions in the x direction.\n",
    "        xError (array-like): Error on each x\n",
    "        feb (bool): If the iamge was taken 25.02.2025\n",
    "        march (bool): If the iamge was taken 05.03.2025\n",
    "\n",
    "    returns:\n",
    "        wavelengths (array-like): Wavelength values for each x\n",
    "        wavelengthErrors (array-like): Wavelength errors for each x\n",
    "\n",
    "    \"\"\"\n",
    "    # Params\n",
    "    a = -1.8 * (10**(-4))\n",
    "    c = 359230\n",
    "\n",
    "    # Order number\n",
    "    m = 54\n",
    "\n",
    "    # Depending on date\n",
    "    if feb and march:\n",
    "        raise ValueError(\"Both 'feb' and 'march' cannot be True at the same time.\")\n",
    "    elif feb:\n",
    "        b = -3.3079\n",
    "    elif march:\n",
    "        b = -3.3158\n",
    "    else:\n",
    "        raise ValueError(\"Either 'feb' or 'march' must be True.\")\n",
    "\n",
    "    # Horizontal Flip\n",
    "    xFlipped = np.flip(x)\n",
    "    xErrorFlipped = np.flip(xError)\n",
    "\n",
    "    # Calculate Wavelengths\n",
    "    wavelengths = ((a * (xFlipped**2)) + (b * xFlipped) + c)/m\n",
    "\n",
    "    # Calculate Error:\n",
    "    wavelengthErrors = (1/m)*((2*a*xFlipped) + (b))* xErrorFlipped\n",
    "\n",
    "\n",
    "    return wavelengths, wavelengthErrors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_number=0\n",
    "initial_guess = [-1, -3, 1000, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/q9sj039x3qqgdn5jb6y2c8k00000gn/T/ipykernel_85814/400182132.py:2: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sigma_dark = np.sqrt(np.mean(Dark_images_bs, axis=0)) / np.sqrt(np.abs(len(Dark_images_bs)))\n",
      "/Users/kiradavidoff/.pyenv/versions/3.10.6/envs/Halpha/lib/python3.10/site-packages/scipy/optimize/_minpack_py.py:906: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  warnings.warn('Covariance of the parameters could not be estimated',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increase\n",
      "CHI\n",
      "6580.099053122591 -0.65567041783249\n",
      "COV\n",
      "6580.099053122591 -0.06004507156615422\n",
      "ImageNumber = 1\n",
      "\n",
      "\n",
      "               VALUE              CHI SQUARED ERROR     COVARIANCE MATRIX ERROR\n",
      "amplitude   -0.5121746030133795 +- 0.04330000166126691 +- 0.004601191881201737\n",
      "position     1110.6284815314825 +- 9.528999998592326    +- 0.872648012336492\n",
      "\n",
      "position (Angstrom):  6580.099053122591+- -0.65567041783249+- -0.06004507156615422\n",
      "\n",
      "\n",
      "SN (CHI): 11.828512317853658\n",
      "SN (COV): 111.31346317154893\n"
     ]
    }
   ],
   "source": [
    "noise_full_image=sigma_dbl()\n",
    "\n",
    "noise_subset =back(noise_full_image)\n",
    "\n",
    "image_subset =img()\n",
    "\n",
    "alf_Dra_p001_02_1D_corrected, noise_corrected=ha.MedianClipRolling(image_subset,noise_subset,clip=3, windowSize=25)\n",
    "\n",
    "continium_normarlisedd,normalised_errr= ha.Normalise( alf_Dra_p001_02_1D_corrected,noise_corrected, 700, 1300)\n",
    "\n",
    "popt_1, pcov_1, sample_nw_1, sigma_range_1, x_range_1 =chi(continium_normarlisedd,normalised_errr)\n",
    "\n",
    "final(popt_1, pcov_1, sample_nw_1, sigma_range_1, x_range_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_number=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/q9sj039x3qqgdn5jb6y2c8k00000gn/T/ipykernel_85814/400182132.py:2: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sigma_dark = np.sqrt(np.mean(Dark_images_bs, axis=0)) / np.sqrt(np.abs(len(Dark_images_bs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increase\n",
      "CHI\n",
      "6580.092364065801 -0.7094160644947113\n",
      "COV\n",
      "6580.092364065801 -0.05859643675404206\n",
      "ImageNumber = 1\n",
      "\n",
      "\n",
      "               VALUE              CHI SQUARED ERROR     COVARIANCE MATRIX ERROR\n",
      "amplitude   -0.5202958515385077 +- 0.04810000166142592 +- 0.004599939076739751\n",
      "position     1110.7256945827876 +- 10.309999998573858    +- 0.8515866683691522\n",
      "\n",
      "position (Angstrom):  6580.092364065801+- -0.7094160644947113+- -0.05859643675404206\n",
      "\n",
      "\n",
      "SN (CHI): 10.81696119681763\n",
      "SN (COV): 113.109291853333\n"
     ]
    }
   ],
   "source": [
    "noise_full_image=sigma_dbl()\n",
    "\n",
    "noise_subset =back(noise_full_image)\n",
    "\n",
    "image_subset =img()\n",
    "\n",
    "alf_Dra_p001_02_1D_corrected, noise_corrected=ha.MedianClipRolling(image_subset,noise_subset,clip=3, windowSize=25)\n",
    "\n",
    "continium_normarlisedd,normalised_errr= ha.Normalise( alf_Dra_p001_02_1D_corrected,noise_corrected, 700, 1300)\n",
    "\n",
    "popt_1, pcov_1, sample_nw_1, sigma_range_1, x_range_1 =chi(continium_normarlisedd,normalised_errr)\n",
    "\n",
    "final(popt_1, pcov_1, sample_nw_1, sigma_range_1, x_range_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_number=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/q9sj039x3qqgdn5jb6y2c8k00000gn/T/ipykernel_85814/400182132.py:2: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sigma_dark = np.sqrt(np.mean(Dark_images_bs, axis=0)) / np.sqrt(np.abs(len(Dark_images_bs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increase\n",
      "CHI\n",
      "6580.099406253743 -0.7652122039138661\n",
      "COV\n",
      "6580.099406253743 -0.06126807450879526\n",
      "ImageNumber = 1\n",
      "\n",
      "\n",
      "               VALUE              CHI SQUARED ERROR     COVARIANCE MATRIX ERROR\n",
      "amplitude   -0.5170363456687178 +- 0.05390000166161368 +- 0.00500732930372279\n",
      "position     1110.623349398794 +- 11.12099999855468    +- 0.8904226213836701\n",
      "\n",
      "position (Angstrom):  6580.099406253743+- -0.7652122039138661+- -0.06126807450879526\n",
      "\n",
      "\n",
      "SN (CHI): 9.592510755652517\n",
      "SN (COV): 103.25591034812066\n"
     ]
    }
   ],
   "source": [
    "noise_full_image=sigma_dbl()\n",
    "\n",
    "noise_subset =back(noise_full_image)\n",
    "\n",
    "image_subset =img()\n",
    "\n",
    "alf_Dra_p001_02_1D_corrected, noise_corrected=ha.MedianClipRolling(image_subset,noise_subset,clip=3, windowSize=25)\n",
    "\n",
    "continium_normarlisedd,normalised_errr= ha.Normalise( alf_Dra_p001_02_1D_corrected,noise_corrected, 700, 1300)\n",
    "\n",
    "popt_1, pcov_1, sample_nw_1, sigma_range_1, x_range_1 =chi(continium_normarlisedd,normalised_errr)\n",
    "\n",
    "final(popt_1, pcov_1, sample_nw_1, sigma_range_1, x_range_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/q9sj039x3qqgdn5jb6y2c8k00000gn/T/ipykernel_85814/400182132.py:2: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sigma_dark = np.sqrt(np.mean(Dark_images_bs, axis=0)) / np.sqrt(np.abs(len(Dark_images_bs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increase\n",
      "CHI\n",
      "6580.755143113999 -0.5906509986301447\n",
      "COV\n",
      "6580.755143113999 -0.048832162434407834\n",
      "ImageNumber = 1\n",
      "\n",
      "\n",
      "               VALUE              CHI SQUARED ERROR     COVARIANCE MATRIX ERROR\n",
      "amplitude   -0.5306219549891863 +- 0.042300001661231934 +- 0.004058175859320872\n",
      "position     1101.08897526482 +- 8.591999998614483    +- 0.7103449254159294\n",
      "\n",
      "position (Angstrom):  6580.755143113999+- -0.5906509986301447+- -0.048832162434407834\n",
      "\n",
      "\n",
      "SN (CHI): 12.544253762417762\n",
      "SN (COV): 130.7538099341966\n"
     ]
    }
   ],
   "source": [
    "image_number=3\n",
    "\n",
    "noise_full_image=sigma_dbl()\n",
    "\n",
    "noise_subset =back(noise_full_image)\n",
    "\n",
    "image_subset =img()\n",
    "\n",
    "alf_Dra_p001_02_1D_corrected, noise_corrected=ha.MedianClipRolling(image_subset,noise_subset,clip=3, windowSize=25)\n",
    "\n",
    "continium_normarlisedd,normalised_errr= ha.Normalise( alf_Dra_p001_02_1D_corrected,noise_corrected, 700, 1300)\n",
    "\n",
    "popt_1, pcov_1, sample_nw_1, sigma_range_1, x_range_1 =chi(continium_normarlisedd,normalised_errr)\n",
    "\n",
    "final(popt_1, pcov_1, sample_nw_1, sigma_range_1, x_range_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/q9sj039x3qqgdn5jb6y2c8k00000gn/T/ipykernel_85814/400182132.py:2: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sigma_dark = np.sqrt(np.mean(Dark_images_bs, axis=0)) / np.sqrt(np.abs(len(Dark_images_bs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increase\n",
      "CHI\n",
      "6580.777465793314 -0.6469322044850008\n",
      "COV\n",
      "6580.777465793314 -0.050014598878803086\n",
      "ImageNumber = 1\n",
      "\n",
      "\n",
      "               VALUE              CHI SQUARED ERROR     COVARIANCE MATRIX ERROR\n",
      "amplitude   -0.5294343541474003 +- 0.04760000166141043 +- 0.004256225903109805\n",
      "position     1100.7642496974797 +- 9.410999998595116    +- 0.727568339796669\n",
      "\n",
      "position (Angstrom):  6580.777465793314+- -0.6469322044850008+- -0.050014598878803086\n",
      "\n",
      "\n",
      "SN (CHI): 11.122570077064\n",
      "SN (COV): 124.39056718313985\n"
     ]
    }
   ],
   "source": [
    "image_number=4\n",
    "\n",
    "noise_full_image=sigma_dbl()\n",
    "\n",
    "noise_subset =back(noise_full_image)\n",
    "\n",
    "image_subset =img()\n",
    "\n",
    "alf_Dra_p001_02_1D_corrected, noise_corrected=ha.MedianClipRolling(image_subset,noise_subset,clip=3, windowSize=25)\n",
    "\n",
    "continium_normarlisedd,normalised_errr= ha.Normalise( alf_Dra_p001_02_1D_corrected,noise_corrected, 700, 1300)\n",
    "\n",
    "popt_1, pcov_1, sample_nw_1, sigma_range_1, x_range_1 =chi(continium_normarlisedd,normalised_errr)\n",
    "\n",
    "final(popt_1, pcov_1, sample_nw_1, sigma_range_1, x_range_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/q9sj039x3qqgdn5jb6y2c8k00000gn/T/ipykernel_85814/400182132.py:2: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sigma_dark = np.sqrt(np.mean(Dark_images_bs, axis=0)) / np.sqrt(np.abs(len(Dark_images_bs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increase\n",
      "CHI\n",
      "6580.7880336160615 -0.5150083746857386\n",
      "COV\n",
      "6580.7880336160615 -0.055674076874897914\n",
      "ImageNumber = 1\n",
      "\n",
      "\n",
      "               VALUE              CHI SQUARED ERROR     COVARIANCE MATRIX ERROR\n",
      "amplitude   -0.527305995246215 +- 0.033400001660935374 +- 0.004132679298031986\n",
      "position     1100.6105171725392 +- 7.491999998640495    +- 0.8099095167638182\n",
      "\n",
      "position (Angstrom):  6580.7880336160615+- -0.5150083746857386+- -0.055674076874897914\n",
      "\n",
      "\n",
      "SN (CHI): 15.78760386299477\n",
      "SN (COV): 127.59422089619252\n"
     ]
    }
   ],
   "source": [
    "image_number=5\n",
    "\n",
    "noise_full_image=sigma_dbl()\n",
    "\n",
    "noise_subset =back(noise_full_image)\n",
    "\n",
    "image_subset =img()\n",
    "\n",
    "alf_Dra_p001_02_1D_corrected, noise_corrected=ha.MedianClipRolling(image_subset,noise_subset,clip=3, windowSize=25)\n",
    "\n",
    "continium_normarlisedd,normalised_errr= ha.Normalise( alf_Dra_p001_02_1D_corrected,noise_corrected, 700, 1300)\n",
    "\n",
    "popt_1, pcov_1, sample_nw_1, sigma_range_1, x_range_1 =chi(continium_normarlisedd,normalised_errr)\n",
    "\n",
    "final(popt_1, pcov_1, sample_nw_1, sigma_range_1, x_range_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/q9sj039x3qqgdn5jb6y2c8k00000gn/T/ipykernel_85814/400182132.py:2: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sigma_dark = np.sqrt(np.mean(Dark_images_bs, axis=0)) / np.sqrt(np.abs(len(Dark_images_bs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increase\n",
      "CHI\n",
      "6581.186161571973 -1.768676772685751\n",
      "COV\n",
      "6581.186161571973 -0.06586096531322018\n",
      "ImageNumber = 1\n",
      "\n",
      "\n",
      "               VALUE              CHI SQUARED ERROR     COVARIANCE MATRIX ERROR\n",
      "amplitude   -0.4442055177471279 +- 0.07250000166223358 +- 0.003706672097738374\n",
      "position     1094.8171884360825 +- 25.743999998208892    +- 0.9586402202426775\n",
      "\n",
      "position (Angstrom):  6581.186161571973+- -1.768676772685751+- -0.06586096531322018\n",
      "\n",
      "\n",
      "SN (CHI): 6.126972518105772\n",
      "SN (COV): 119.83944250643587\n"
     ]
    }
   ],
   "source": [
    "image_number=6\n",
    "\n",
    "noise_full_image=sigma_dbl()\n",
    "\n",
    "noise_subset =back(noise_full_image)\n",
    "\n",
    "image_subset =img()\n",
    "\n",
    "alf_Dra_p001_02_1D_corrected, noise_corrected=ha.MedianClipRolling(image_subset,noise_subset,clip=3, windowSize=25)\n",
    "\n",
    "continium_normarlisedd,normalised_errr= ha.Normalise( alf_Dra_p001_02_1D_corrected,noise_corrected, 700, 1300)\n",
    "\n",
    "popt_1, pcov_1, sample_nw_1, sigma_range_1, x_range_1 =chi(continium_normarlisedd,normalised_errr)\n",
    "\n",
    "final(popt_1, pcov_1, sample_nw_1, sigma_range_1, x_range_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/q9sj039x3qqgdn5jb6y2c8k00000gn/T/ipykernel_85814/1229552526.py:2: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sigma_dark = np.sqrt(np.mean(Dark_images_bs, axis=0)) / np.sqrt(np.abs(len(Dark_images_bs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4907465389090098\n",
      "ImageNumber = 8\n",
      "\n",
      "               VALUE              CHI/MC ERROR           COVARIANCE-MATRIX ERROR\n",
      "amplitude   0.20331579700936292 +- 0.003162277512764021        +- 0.3798392583465926\n",
      "position    1074.203321376201 +- 3.9855404268031567         +- 11.82803346148023\n",
      "\n",
      "position (Angstrom):  6582.600969025237 +- -0.2732688152262276      +- -0.8109898142640308\n",
      "\n",
      "SN (CHI): 64.29410328116734\n",
      "SN (COV): 0.5352679917667779\n"
     ]
    }
   ],
   "source": [
    "image_number=7\n",
    "\n",
    "noise_full_image=sigma_dbl()\n",
    "\n",
    "noise_subset =back(noise_full_image)\n",
    "\n",
    "image_subset =img()\n",
    "\n",
    "alf_Dra_p001_02_1D_corrected, noise_corrected=ha.MedianClipRolling(image_subset,noise_subset,clip=3, windowSize=25)\n",
    "\n",
    "\n",
    "continium_normarlisedd,normalised_errr= ha.Normalise( alf_Dra_p001_02_1D_corrected,noise_corrected, 700, 1300)\n",
    "\n",
    "amplitude, amplitude_err,popt_am,pcov_am=sn_dl(continium_normarlisedd,normalised_errr)\n",
    "\n",
    "position,pos_err,popt_pos,pcov_pos= pos_dl(continium_normarlisedd,normalised_errr)\n",
    "\n",
    "final_double_lorentz(amplitude, amplitude_err, position, pos_err, pcov_pos, image_number=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/q9sj039x3qqgdn5jb6y2c8k00000gn/T/ipykernel_34125/400182132.py:2: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sigma_dark = np.sqrt(np.mean(Dark_images_bs, axis=0)) / np.sqrt(np.abs(len(Dark_images_bs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increase\n",
      "CHI\n",
      "6581.187352326717 -1.8083150651919655\n",
      "COV\n",
      "6581.187352326717 -0.06613350886145562\n",
      "ImageNumber = 1\n",
      "\n",
      "\n",
      "               VALUE              CHI SQUARED ERROR     COVARIANCE MATRIX ERROR\n",
      "amplitude   -0.4445695443844575 +- 0.07420000166229146 +- 0.0037284614437420797\n",
      "position     1094.7998563738345 +- 26.320999998195248    +- 0.9626088507083422\n",
      "\n",
      "position (Angstrom):  6581.187352326717+- -1.8083150651919655+- -0.06613350886145562\n",
      "\n",
      "\n",
      "SN (CHI): 5.991503159364326\n",
      "SN (COV): 119.23672836435829\n"
     ]
    }
   ],
   "source": [
    "image_number=7\n",
    "\n",
    "noise_full_image=sigma_dbl()\n",
    "\n",
    "noise_subset =back(noise_full_image)\n",
    "\n",
    "image_subset =img()\n",
    "\n",
    "alf_Dra_p001_02_1D_corrected, noise_corrected=ha.MedianClipRolling(image_subset,noise_subset,clip=3, windowSize=25)\n",
    "\n",
    "continium_normarlisedd,normalised_errr= ha.Normalise( alf_Dra_p001_02_1D_corrected,noise_corrected, 700, 1300)\n",
    "\n",
    "popt_1, pcov_1, sample_nw_1, sigma_range_1, x_range_1 =chi(continium_normarlisedd,normalised_errr)\n",
    "\n",
    "final(popt_1, pcov_1, sample_nw_1, sigma_range_1, x_range_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/q9sj039x3qqgdn5jb6y2c8k00000gn/T/ipykernel_85814/1229552526.py:2: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sigma_dark = np.sqrt(np.mean(Dark_images_bs, axis=0)) / np.sqrt(np.abs(len(Dark_images_bs)))\n",
      "/Users/kiradavidoff/.pyenv/versions/3.10.6/envs/Halpha/lib/python3.10/site-packages/scipy/optimize/_minpack_py.py:906: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  warnings.warn('Covariance of the parameters could not be estimated',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increase\n",
      "CHI\n",
      "6581.130925170299 -2.42167669459571\n",
      "COV\n",
      "6581.130925170299 -0.09418430319809497\n",
      "ImageNumber = 1\n",
      "\n",
      "\n",
      "               VALUE              CHI SQUARED ERROR     COVARIANCE MATRIX ERROR\n",
      "amplitude   -0.4454344166501077 +- 0.10830000166342196 +- 0.006226284736491229\n",
      "position     1095.6211513085343 +- 35.2459999979842    +- 1.370794027847882\n",
      "\n",
      "position (Angstrom):  6581.130925170299+- -2.42167669459571+- -0.09418430319809497\n",
      "\n",
      "\n",
      "SN (CHI): 4.112967772931734\n",
      "SN (COV): 71.54096471680616\n"
     ]
    }
   ],
   "source": [
    "image_number=8\n",
    "\n",
    "noise_full_image=sigma_dbl()\n",
    "\n",
    "noise_subset =back(noise_full_image)\n",
    "\n",
    "image_subset =img()\n",
    "\n",
    "alf_Dra_p001_02_1D_corrected, noise_corrected=ha.MedianClipRolling(image_subset,noise_subset,clip=3, windowSize=25)\n",
    "\n",
    "\n",
    "continium_normarlisedd,normalised_errr= ha.Normalise( alf_Dra_p001_02_1D_corrected,noise_corrected, 700, 1300)\n",
    "\n",
    "popt_1, pcov_1, sample_nw_1, sigma_range_1, x_range_1 =chi(continium_normarlisedd,normalised_errr)\n",
    "\n",
    "final(popt_1, pcov_1, sample_nw_1, sigma_range_1, x_range_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/q9sj039x3qqgdn5jb6y2c8k00000gn/T/ipykernel_85814/1229552526.py:2: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sigma_dark = np.sqrt(np.mean(Dark_images_bs, axis=0)) / np.sqrt(np.abs(len(Dark_images_bs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.39627178464614\n",
      "ImageNumber = 8\n",
      "\n",
      "               VALUE              CHI/MC ERROR           COVARIANCE-MATRIX ERROR\n",
      "amplitude   -0.6155350071010581 +- 0.011401754087440392        +- 0.015831363185997826\n",
      "position    1103.5466274813746 +- 1.4933217996832595         +- 2.942806886545041\n",
      "\n",
      "position (Angstrom):  6580.586173406901 +- -0.10268182422726493      +- -0.20234940621846875\n",
      "\n",
      "SN (CHI): 53.9859921886143\n",
      "SN (COV): 38.880733128873764\n"
     ]
    }
   ],
   "source": [
    "image_number=8\n",
    "\n",
    "noise_full_image=sigma_dbl()\n",
    "\n",
    "noise_subset =back(noise_full_image)\n",
    "\n",
    "image_subset =img()\n",
    "\n",
    "alf_Dra_p001_02_1D_corrected, noise_corrected=ha.MedianClipRolling(image_subset,noise_subset,clip=3, windowSize=25)\n",
    "\n",
    "\n",
    "continium_normarlisedd,normalised_errr= ha.Normalise( alf_Dra_p001_02_1D_corrected,noise_corrected, 700, 1300)\n",
    "\n",
    "amplitude, amplitude_err,popt_am,pcov_am=sn_dl(continium_normarlisedd,normalised_errr)\n",
    "\n",
    "position,pos_err,popt_pos,pcov_pos= pos_dl(continium_normarlisedd,normalised_errr)\n",
    "\n",
    "final_double_lorentz(amplitude, amplitude_err, position, pos_err, pcov_pos, image_number=8)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Halpha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
